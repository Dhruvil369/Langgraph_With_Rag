# 🚀 LangChain + MultiRAG Implementation

An advanced implementation combining the power of **LangChai** with **Multi-Document Retrieval-Augmented Generation (MultiRAG)** to build a scalable and efficient question-answering system.

---

## 📖 About the Project

This project demonstrates a **Multi-RAG pipeline** using LangChain to enable:
- Document chunking and embedding.
- Multi-source retrieval.
- Context-rich generation using LLMs.

Ideal for use cases like knowledge base Q&A, chatbot agents, document intelligence, and more.

---

## 🛠️ Tech Stack

- **[LangChain](https://www.langchain.com/)** – Orchestration framework for LLMs.
- **Vector Store** – FAISS / Chroma / Pinecone (configurable).
- **Embeddings** – OpenAI / HuggingFace / BGE / Cohere.
- **LLMs** –  Google Gemini.
- **Python** – Core implementation language.

---

## ✨ Features

- 📚 Supports multiple document ingestion.
- 🔍 Multi-source retrieval (Multi-RAG).
- 🧠 Smart context injection before generation.
- ⚙️ Easily configurable components (LLM, embedding, vector DB).

---

## 🧰 Setup Instructions

1. **Clone the repo**:
   ```bash
   git clone https://github.com/Dhruvil369/Langgraph_With_Rag.git
   cd Langgraph_With_Rag
   Python FileName.py
