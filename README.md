# ğŸš€ LangChain + MultiRAG Implementation

An advanced implementation combining the power of **LangChai** with **Multi-Document Retrieval-Augmented Generation (MultiRAG)** to build a scalable and efficient question-answering system.

---

## ğŸ“– About the Project

This project demonstrates a **Multi-RAG pipeline** using LangChain to enable:
- Document chunking and embedding.
- Multi-source retrieval.
- Context-rich generation using LLMs.

Ideal for use cases like knowledge base Q&A, chatbot agents, document intelligence, and more.

---

## ğŸ› ï¸ Tech Stack

- **[LangChain](https://www.langchain.com/)** â€“ Orchestration framework for LLMs.
- **Vector Store** â€“ FAISS / Chroma / Pinecone (configurable).
- **Embeddings** â€“ OpenAI / HuggingFace / BGE / Cohere.
- **LLMs** â€“  Google Gemini.
- **Python** â€“ Core implementation language.

---

## âœ¨ Features

- ğŸ“š Supports multiple document ingestion.
- ğŸ” Multi-source retrieval (Multi-RAG).
- ğŸ§  Smart context injection before generation.
- âš™ï¸ Easily configurable components (LLM, embedding, vector DB).

---

## ğŸ§° Setup Instructions

1. **Clone the repo**:
   ```bash
   git clone https://github.com/Dhruvil369/Langgraph_With_Rag.git
   cd Langgraph_With_Rag
   Python FileName.py
